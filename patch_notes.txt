Nov 27 2023
    I started adding a database system.
        its a mess. considering the save point system i made, its a little unnecessary, and i dont have actual access to the gamefaqs database, which means whatever database i have here is going to be a shallow imitation of the real one.
        storing dl'd data in a database has ramifications of needing a more complicated viewer than notepad, but the payment in "work experience" is vital
        its not done, and after going a little nuts, i called it off before continuing the pickle way
    deleted compress_games.py, didn't need it
    deleted scraper_vars.py, never needed it
    added get_guides.py
        coming along much slower than i would have wanted. needed to make decisions, solve problems
        one game can be feature in many different consoles with multiple names in different languages. how to only download the guides for a game once, rather than consoles by names times?
        solved, i think. get the game, get its aliases on page, get the guides, mark each console file with the game as complete
    get_console_links.py now saves a second console list file, for checking progress during guide downloading
    Author's note: This should have been a branch. I really just followed my passion here, without a care for structure or order.

Nov 21 2023
    Moved the "Elaborate "Thread" Locking System" into a generic, reusable function
    moving onto the part where i gotta start playing with BIG data, think i might need to do a database
    if i do a database tho, i implicitly need an actual user interface to see the guides.
    concered about whats next honestly. could just load up all the txt files sorted into alphabetical folders, 
        but there's a reason why web sites have crazy backends. need to research building a gui


Nov 17 2023
    added an elaborate "Thread" Locking System
        if this app isn't fetching web data, its writing files. and since this is designed to be stopped and re-run at any time (and this is taking up MOST OF THE WORK ON THIS PROJECT), I needed a way to guranatee that, when interruped, work wouldn't be lost, missing, or corrupt.
        pkl_io.py - added atomicwrites: pip module that claims to only write a file if all the data is applied
        get_game_links.py - Added force_save(): attempts to prevent keyboard interrupts with some cute loop-retrying functionality. will need to be expanded later. will still close the program if interrupted three times
    get_game_links.py - actually gets game links now! and saves them to their appropriate console! games are unique, there will be MANY duplicates and duplicate guides. this will also need work
    renamed web_consts.py -> constants.py
    added file locations to constants.py
        this allows the run_func pointers in the Main_Step class not require any parameters. any data each module needs is a constant, and lives in the appropriate file
        also allows the stupid 'previous_step' stuff in main_gamefaqs_scraper.py to be removed.
    I learned about the unpacking operator in python!


Nov 14 2023
    Added bizarre class in get_game_links thats supposed to block keyboard interrupts. will need to use later
    offloading more file io tedium into the actual file io module. this includes making sure files being created/read are in the right folder, have the right file suffix, and actually exist
    uncommenting things as I go in get_game_links. currently in a runnable state, doesn't actually save any links yet

Nov 9 2023
    Created progress_data_strctures.py
        probably the wrong name, but holds the classes that ultimately get written to pickle files
        split `Scraping_Step_Struct` into three steps: Main_Step, File_Step, and Link_Step
            furter revision will be necessary to these, but they're in a good place data-managment wise, even if they don't make much sense
    Created web_consts.py
        probably the wrong name, but holds the url pieces and common soup functions to be used all over the code
    Created get_game_links.py
        the next step in the scraping, finding the links of all the games associated with a system. ultimately, each game will be not really 
        be associated with its platform, but gotta start somewhere
    I have a linter in sublime now!! proper code styling here i come

    `test` var added to get_console_links.py. this file and step are nearly finalized
    added `unpickle` function to pkl_io.py


Nov 9 2023
    Step_Scraping_Struct makes use of function pointers. starting to understand modules...honestly wondering why python even has classes at this point

Nov 8 2023
    Further IO adjustments, mainly cleaning up the weird "check completion" style functions I left lying around
        added append_all_to_pkl()
    Split functions that did two things into their own specific functions. ex: check the progress file, but create it if it isn't there
    Progress file updates when steps complete

Nov 7 2023
    redid file reading and writing to make more sense
        added helper functions, no reading/writing is inline anymore
        moved io functions to a new file, pkl_io.py
    making the Scraping_Step_Struct more of a real object, for extensibility purposes
        gonna have to rename that in the future. pythoners must have some sort of agreed naming standard
    added a test function, will be useful going forward to not have to make web calls all the time to test
    TODO: update get_console_links.py to use pkl_io